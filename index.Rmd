---
title: "Biostatistics Methods ç”Ÿç‰©ç»Ÿè®¡å­¦æ–¹æ³•"
output: 
  html_document:
    toc: true
    toc_float: true
    collapsed: true
    code_folding: hide
    number_sections: true
---

# Introduction

## Statistics & Biostatistics {.tabset}

### Some Definitions (æ€»ä½“ã€æ ·æœ¬ã€å‚æ•°ã€ç»Ÿè®¡é‡ã€å˜é‡)

* `Population`: the complete collection of units (individuals or objects) of interest in a study.

* `Parameter (the truth)`: any descriptive measure based on a population (a single-value parameter or a complicated function)

* `Sample`: a smaller subset of the population of interest

* `Statistic (approximation of the truth, prone to error)`: any descriptive measure (of the parameter) based on a sample (synonym: Estimator)

â€”â€”The true Parameter is invariant to the Sample.

* `Variable`: a characteristic of each element of a population or sample

### Sampling (æŠ½æ ·)

![](Sampling Scheme.jpg)

Statistical inference allows generalization from the sample only to the population from which the sample came from (assuming no sampling and response bias!).

If we want to make inference about the target population, we have to make sure that the population from which the sample came from is similar to the target population.

**Sampling Populations**

* The ability to obtain reliable measures of population depends critically on how we sample populations.

Properties of good samples:

* Low sampling error, focus on `precision`

* `Accurate` (or unbiased) estimates

Bias v.s. Variance

* `Bias`: tendency of being inaccurate

* `Variance`: uncertainty due to randomness of samples

### Types of (structured) Data

* `Qualitative data`: measurements expressed not in terms of numbers but in types or categories.

* `Qualitative variables` can be subdivided into: 

`Ordinal variables`: ordered series (e.g., preference, disease severity)

`Nominal variables`: no inherent order or ranking (e.g., blood type)

`Binary variables`: only two options (e.g., pass/fail, yes/no)

* `Quantitative data`: measurements expressed in terms of numbers:
e.g., weight, blood pressure, survival time, etc.

* `Quantitative variables` can also be subdivided into:

`Discrete variables`: usually there are gaps between the values
e.g., # of pregnancies

`Continuous variable`s: have a set of all possible values within an
interval. e.g., body mass index (BMI)


### Sources of Data

* `Published Source`: government, business, sports statistics are collected and presented in press, online, etc.

* `Experimental Study`: researchers deliberately influence events and investigate the effects of an intervention

* `Survey`: researchers select sample of individuals and record their responses to questions

* `Observational Study`: researchers collect information on the attributesor measurements of interest, without influencing the events

### Study Design

* Experimental

![](Experimental Studies.jpg)

* Observational

Observational studies are to be contrasted with experiments.

â€¢ No intervention

â€¢ Data collected on an already existing system (practical, less expensive, feasible)

Types of observational studies:

â€¢ Case study: descriptive characteristics of a single subject

â€¢ Case-control study

![](Case-Control Study.jpg)

â€¢ Cross-sectional study

![](Cross-Sectional Study.jpg)

â€¢ Cohort studies

![](Cohort Study.jpg)

## R code -- Data Maniplulation {.tabset}

### Importing Data è¯»å–æ•°æ®

Here we read csv files `lowbwt_Low.csv` and `lowbwt_Normal.csv`

You will need to change the working directory to your personal file location.

```{r, message=FALSE}
# read and name data è¯»å–å¹¶å‘½åæ•°æ®
low_birth = read.csv("Module 1/lowbwt_Low.csv")
norm_birth = read.csv("Module 1/lowbwt_Normal.csv")
```

### Examine Data Attributes æ£€æŸ¥æ•°æ®å±æ€§

```{r, message=FALSE}
# Variable names åˆ—å˜é‡åç§°
names(low_birth)    

# Data dimension: rows x columns; here: 59 rows and 3 columns æ•°æ®ç»´åº¦ï¼šè¡ŒÃ—åˆ—
dim(low_birth)

# Number of rows è¡Œæ•°
nrow(low_birth)

# Number of columns åˆ—æ•°
ncol(low_birth)

# Head and Tail observations å¼€å¤´å’Œç»“å°¾çš„è§‚å¯Ÿé‡
head(low_birth)
tail(low_birth)

# Check for number of missing values æ£€æŸ¥ç¼ºå¤±å€¼æ•°é‡
sum(is.na(low_birth))

# Examine the classes of each column æ£€æŸ¥æ¯åˆ—çš„å˜é‡ç±»å‹
str(low_birth)

# Tabulate variable smoke ???
table(low_birth$smoke)
```

### Data Manipulation using `dplyr` ç”¨â€œdplyâ€è¿›è¡Œæ•°æ®æ¨¡æ‹Ÿ

Note: to apply these changes to the existing data, you must reassign the change.

i.e. `low_birth = filter(low_birth, age < 20)`

NOTE: you will need to install the `{tidyverse}` package.  Run `install.packages("tidyverse")` in the Console.

```{r, message=FALSE}
library(tidyverse)
```

```{r, message=FALSE}
# Select only column/variable age åªé€‰æ‹©ä¸€åˆ—å˜é‡
dplyr::select(low_birth, age)

# Keep only rows where 'age' is less than 20 åªä¿ç•™å¹´é¾„ï¼œ20çš„è¡Œ
filter(low_birth, age < 20)

# Select rows that contain missing data é€‰æ‹©åŒ…æ‹¬ç¼ºå¤±å€¼çš„è¡Œ
filter(low_birth, is.na(age))

# Remove column age å»æ‰â€œå¹´é¾„â€è¿™ä¸€åˆ—
dplyr::select(low_birth, -age)

# Filter rows: select all 25+ yrs old, smokers é€‰æ‹©æ‰€æœ‰å¹´é¾„ï¼25ï¼ŒæŠ½çƒŸçš„è¡Œ
filter(low_birth, age > 25 & smoke == "1") 

# Ordering data by variable/column 'id' æŒ‰ç…§â€œidâ€å¯¹æ•°æ®æ’åˆ—
arrange(low_birth, id)

# Arrange by id in descending order æŒ‰idé™åºå¯¹æ•°æ®æ’åˆ—
arrange(low_birth, desc(id))

# Order by multiple columns/variables æŒ‰ç…§å¤šåˆ—å˜é‡æ’åº
arrange(low_birth, smoke, desc(age))

# Rename variable 'smoke' to 'Smoking_Status' å¯¹â€œæŠ½çƒŸâ€é‡æ–°å‘½å
rename(low_birth, Smoking_Status = smoke)

# Create a variable for log of 'age' åˆ›å»ºæ–°çš„å˜é‡ä¸ºâ€œå¹´é¾„â€çš„å¯¹æ•°
mutate(low_birth, log_age = log(age))

# Centering the data by subtracting the mean from variable 'age' ä»å˜é‡ "å¹´é¾„ "ä¸­å‡å»å¹³å‡å€¼ï¼Œä½¿æ•°æ®å±…ä¸­
mutate(low_birth, center_age = age - mean(age))

# Use case_when function to create new age categories ä½¿ç”¨ case_when å‡½æ•°åˆ›å»ºæ–°çš„å¹´é¾„ç±»åˆ«
# Cat 1: Age < 25; Cat 2: 25 < Age < 30. Cat 3: Age > 30
mutate(low_birth, new_age = case_when(age < 25 ~ 1,
                                      age >= 25 & age < 30 ~ 2,
                                      age > 30 ~ 3))

```

### Combine Data Sets åˆå¹¶æ•°æ®é›†

```{r,message=FALSE}
# stack low_birth & norm_birth 
low_and_norm = rbind(low_birth, norm_birth)

# combine by specific variable
admin_birth = read.csv("Module 1/lowbwt_Admin.csv")
birth_final = full_join(admin_birth, low_and_norm, by = "id")

# export data 
write.csv(birth_final, file = "Module 1/birth_final.csv")
```



# Descriptive Statistics æè¿°æ€§ç»Ÿè®¡

## Measures of Location = central tendency {.tabset}

### Mean (average)å¹³å‡æ•°

`Definition`: the arithmetic mean represents the sum of all observations divided by the total number of observations

![](Mean.jpg)

* The most common used measure of location

* Overly sensitive to outliers (unusual observations).

* Not appropriate for nominal or categorical variables (how to characterize their mean?)

Convert to binary variables: calculate the frequencies / proportions of blood types A, B and O (the mean of appearance of each type).

* Why â€œmeanâ€ is a good measure of the location / center?

  *  It is the measure that includes all the values in the data set for its calculation, and any change in any of the scores will affect the value of the mean.

### Median (the 50 th percentile) ä¸­ä½æ•°

Definition: The sample median is computed as:

1. If n is odd, median is computed as [(n+1)/2]^th^ largest item in the sample

2. If n is even, computed as the <u>average</u> of (n/2) and [(n/2)+1]^th^ largest items

* Compared to the mean, the median is not affected by every value in the data set including outliers.

* Median is usually an appropriate measure for ordinal data.

### Percentiles ç™¾åˆ†ä½æ•°

Defination: In general the k^th^ percentile is a value such that most k% of the data are smaller than it and (100-k)% are larger than it.

* Median is the 50^th^ percentile

* Quartiles: 25^th^ (Q1), 50^th^ , 75^th^ (Q3)

* Deciles: 10^th^ , 20^th^ , 30^th^ , ...

### Mode ä¼—æ•°

Definition: the most frequently occurring value in the data

It becomes problematic for large number of possible values with infrequent occurrence (continuous variables).

* How to fix this problem?

Discretize the data (intervals, histograms). æ•°æ®ç¦»æ•£åŒ–ï¼ˆåŒºé—´ã€ç›´æ–¹å›¾ï¼‰

### Understanding of location measures

* How do we define the â€œcenterâ€ (location)? 
  * Some point having the smallest dispersion (distance) to the sample points (in sum or average). 
  
* How do we define distance or dispersion?
  * A common choice: (ğ‘¥! âˆ’ğ‘) " as the distance between ğ‘¥! and ğ‘.

* How do we define distance or dispersion?
  * 


# Module 3









# Module 4









# Module 5









# Sampling Distributions æŠ½æ ·åˆ†å¸ƒ

*Law of Large Numbers* â†’ justify the consistency of the sample means

*Central Limit Theorem* â†’ calculate approximate probabilities for sample means

## Sampling Distributions {.tabset}

### Sampling Distributions

The usual way to obtain information regarding a population parameter such as: ğœ‡, ğœ^2, or ğ‘, is by drawing a sample from a population and compute a statistics (sample characteristic).

![](sampling distribution.jpg)

The observed value/statistic depends on the particular sample selected, and it varies from sample to sample â†’ *sampling variability*

The distribution of (the value of) the statistic is called the *sampling distribution*

* The sampling distributions can be described by measures of central tendency and spread. This is informative in predicting how close a statistic falls to the population parameter it estimates (testing, confidence interval).

### Estimation of the Mean of a Distribution



## LLN å¤§æ•°å®šå¾‹ {.tabset}





## CLT ä¸­å¿ƒæé™å®šç† {.tabset}

## R Code






# ç»Ÿè®¡æ¨æ–­æ–¹æ³•

ç½®ä¿¡åŒºé—´â†’æ¨æ–­æ€»ä½“å‚æ•°æ‰€åœ¨çš„èŒƒå›´
å‡è®¾æ£€éªŒâ†’æ¨æ–­æ€»ä½“å‚æ•°ä¹‹é—´æ˜¯å¦ä¸åŒ

## ç½®ä¿¡åŒºé—´ä¼°è®¡

ç½®ä¿¡åŒºé—´ï¼ˆCIï¼‰ï¼šä¼°è®¡å€¼Â±è¯¯å·®èŒƒå›´

é«˜ç½®ä¿¡åº¦=ç»“æœå‡†ç¡®æ€§é«˜

è¯¯å·®èŒƒå›´= ç»“æœç²¾ç¡®æ€§é«˜

å‡å°è¯¯å·®èŒƒå›´mçš„æ–¹æ³•ï¼šâ‘  é€‰æ‹©è¾ƒä½çš„ç½®ä¿¡åº¦â€”â€”å‡å°z' â‘¡ é€‰æ‹©æ›´å¤§çš„æ ·æœ¬é‡n â‘¢ å‡å°æ‹‰å§†è¾¾

## å‡è®¾æ£€éªŒ

å‡è®¾æ£€éªŒ=åè¯æ³•+å°æ¦‚ç‡æ€æƒ³

åŸºæœ¬æ­¥éª¤ï¼š

ï¼ˆä¸€ï¼‰å»ºç«‹å‡è®¾æ£€éªŒï¼Œç¡®å®šæ£€éªŒæ°´å‡†

null hypothesis é›¶å‡è®¾

H0ï¼šä¸¤æ€»ä½“å‡æ•°æ— å·®å¼‚

å¤‡æ‹©å‡è®¾

H1ï¼šä¸¤æ€»ä½“å‡æ•°æœ‰å·®å¼‚

æ£€éªŒæ°´å‡† Î±

ï¼ˆäºŒï¼‰ç»Ÿè®¡é‡çš„é€‰æ‹©ä¸è®¡ç®—

Z = ï¼ˆä¼°è®¡å€¼-å‡è®¾æ£€éªŒå€¼ï¼‰/ä¼°è®¡å€¼çš„æ ‡å‡†è¯¯

ï¼ˆä¸‰ï¼‰è®¡ç®—På€¼ï¼Œåšå‡ºç»Ÿè®¡æ¨æ–­

På€¼ï¼šåœ¨H0æˆç«‹çš„æ¡ä»¶ä¸‹ï¼Œè®¡ç®—ç°æœ‰æ ·æœ¬ç»Ÿè®¡é‡ä»¥åŠæ›´æç«¯æƒ…å†µçš„æ¦‚ç‡ï¼Œç§°ä¸ºå‡è®¾æ£€éªŒçš„På€¼ã€‚

ç»Ÿè®¡æ¨æ–­ç»“è®ºï¼š

è‹¥Pâ‰¤Î±ï¼ŒæŒ‰ç…§Î±æ°´å‡†æ‹’ç»H0ï¼Œæ¥å—H1ï¼Œå¯ä»¥è®¤ä¸ºæ€»ä½“å‚æ•°ä¹‹é—´çš„å·®å¼‚æœ‰ç»Ÿè®¡å­¦æ„ä¹‰ã€‚
è‹¥Pâ‰¥Î±ï¼ŒæŒ‰ç…§Î±æ°´å‡†ä¸æ‹’ç»H0ï¼Œå°šä¸èƒ½è®¤ä¸ºæ€»ä½“å‚æ•°ä¹‹é—´çš„å·®å¼‚æœ‰ç»Ÿè®¡å­¦æ„ä¹‰ã€‚

## æ£€éªŒæ•ˆèƒ½ä¸åŸºäºå†³ç­–çš„æ¨æ–­

æ£€éªŒæ•ˆèƒ½ï¼ˆpower of test)

æ£€éªŒæ°´å‡†ä¸ºÎ±ï¼Œå½“H1ä¸ºçœŸæ—¶ï¼Œå‡è®¾æ£€éªŒèƒ½å¤Ÿæ‹’ç»H0çš„æ¦‚ç‡

ä¸€ç±»é”™è¯¯ï¼šå½“H0ä¸ºçœŸæ—¶ï¼Œæ‹’ç»H0  çŠ¯ä¸€ç±»é”™è¯¯çš„æ¦‚ç‡=æ£€éªŒæ°´å‡†Î±
äºŒç±»é”™è¯¯ï¼šå½“H1ä¸ºçœŸæ—¶ï¼Œæ‹’ç»H1  çŠ¯äºŒç±»é”™è¯¯çš„æ¦‚ç‡=Î²ï¼Œæ£€éªŒæ•ˆèƒ½=1-Î²

# Methods of Inference: One-Sample Mean æ¨æ–­æ–¹æ³•ï¼šå•æ ·æœ¬å‡æ•°{.tabset}

## Samping distribution æŠ½æ ·åˆ†å¸ƒ

* The observed value depends on the particular sample selected, and it varies from sample to sample -> *sampling variability*.

* The distribution of the values of the statistic is called *sampling distribution*.

## Statistical Inferences ç»Ÿè®¡æ¨æ–­{.tabset}

Statistical inferences include:

###  Point Estimation

* A point estimate is a single number computed from the sample, that can be regarded as a plausible value of the population parameter (characteristics).

* Because of sampling variability, rarely is the point estimate exactly equal to the true parameter.

  * Solution: construct a confidence interval (CI) that contains plausible values for the population parameter.


### Interval Estimation

#### æ€»ä½“æ ‡å‡†å·®å·²çŸ¥
  
![](one-sample mean.jpg)

![](one-sample mean1.jpg)

![](one-sample mean2.jpg)

![](one-sample mean3.jpg)

* 95% CI: Interpretations

1. Over the collection of all 95% confidence intervals that could be constructed from repeated samples of size n, 95% of them will contain the true population mean.
1. åœ¨æ‰€æœ‰å¯ä»¥ä»å¤§å°ä¸º n çš„é‡å¤æ ·æœ¬ä¸­æ„å»ºçš„ 95% ç½®ä¿¡åŒºé—´é›†åˆä¸­ï¼Œ95% çš„ç½®ä¿¡åŒºé—´å°†åŒ…å«çœŸå®çš„æ€»ä½“å¹³å‡å€¼ã€‚

2. We are 95% confident that the true population mean lies between the lower and the upper limits of the interval.
2. æˆ‘ä»¬æœ‰ 95% çš„æŠŠæ¡è®¤ä¸ºï¼ŒçœŸå®çš„äººå£å¹³å‡å€¼ä½äºåŒºé—´çš„ä¸‹é™å’Œä¸Šé™ä¹‹é—´ã€‚

#### æ€»ä½“æ ‡å‡†å·®æœªçŸ¥do not know the true ğœ but only know the sample standard deviation?

![](one-sample mean4.jpg)

#### Two vs One-Sided Confidence Intervals

![](Two vs One-Sided Confidence Intervals.jpg)

#### Variance Estimation

![](Variance Estimation.jpg)



### Hypothesis Testing

![](Decision Table.jpg)

![](Type I and Type II Error.jpg)

How to Conduct Hypothesis Testing
1. State the question of interest!
2. Specify the parameter of interest; set up the null/alternative hypotheses and the
significance level;
3. Clearly state the statistical methodology to be used and assumptions - why?;
4. Collect the data;
5. State the test statistic and determine the critical values/region;
6. Interpret the findings in the context of the question/problem;
7. Draw conclusions and compare the results to other findings (if available).

1. è¯´æ˜æ„Ÿå…´è¶£çš„é—®é¢˜ï¼
2. æŒ‡å®šæ„Ÿå…´è¶£çš„å‚æ•°ï¼›è®¾å®šé›¶å‡è®¾/å¤‡æ‹©å‡è®¾å’Œæ˜¾è‘—æ€§æ°´å¹³ï¼›
3. æ˜ç¡®è¯´æ˜è¦ä½¿ç”¨çš„ç»Ÿè®¡æ–¹æ³•å’Œå‡è®¾--ä¸ºä»€ä¹ˆï¼Ÿ
4. 4. æ”¶é›†æ•°æ®ï¼›
5. è¯´æ˜æ£€éªŒç»Ÿè®¡é‡å¹¶ç¡®å®šä¸´ç•Œå€¼/åŒºåŸŸï¼›
6. æ ¹æ®é—®é¢˜çš„èƒŒæ™¯è§£é‡Šç»“æœï¼›
7. å¾—å‡ºç»“è®ºï¼Œå¹¶å°†ç»“æœä¸å…¶ä»–ç»“æœï¼ˆå¦‚æœ‰ï¼‰è¿›è¡Œæ¯”è¾ƒã€‚

#### One-Sample, 1-sided Tests å•æ ·æœ¬å•ä¾§æ£€éªŒ

Known Variance å·²çŸ¥æ ‡å‡†å·®

![](One-Sample, 1-sided Tests.jpg)

![](One-Sample, 1-sided Tests1.jpg)

Unknown Variance æœªçŸ¥æ ‡å‡†å·®

![](One-Sample, 1-sided Tests2.jpg)

#### One-Sample, 2-sided Tests å•æ ·æœ¬åŒä¾§æ£€éªŒ

Known Variance å·²çŸ¥æ ‡å‡†å·®

![](One-Sample, 2-sided Tests.jpg)

Unknown Variance æœªçŸ¥æ ‡å‡†å·®

![](One-Sample, 2-sided Tests2.jpg)

### Prediction









## R code{.tabset}

### Sample Mean Distributions: CLT
Draw 1000 (N) samples of size 10 (n) from an underlying exponential distribution with parameter lambda = 0.3.
ä»å‚æ•°ä¸º lambda = 0.3 çš„æŒ‡æ•°åˆ†å¸ƒä¸­æŠ½å– 1000 (N) ä¸ªå¤§å°ä¸º 10 (n) çš„æ ·æœ¬

```{r, message=FALSE}
#  define parameters å®šä¹‰å‚æ•°
n = 10
N = 1000
lambda = 0.3
set.seed(2)

# create vector of sample means åˆ›å»ºæ ·æœ¬å‡å€¼å‘é‡
sample_means_exp1 = c()
for(i in 1:N){
sample_means_exp1[i] = mean(rexp(n, lambda))
}
```

Calculate their means and variances and draw a histogram to vizualize the sample mean
distribution.
è®¡ç®—å®ƒä»¬çš„å‡å€¼å’Œæ–¹å·®ï¼Œå¹¶ç»˜åˆ¶ç›´æ–¹å›¾ä»¥æ˜¾ç¤ºæ ·æœ¬å‡å€¼åˆ†å¸ƒã€‚

```{r,message=FALSE}
mean(sample_means_exp1)
var(sample_means_exp1)
hist(sample_means_exp1,
main = "Samples of Size n = 10 from Exp(0.3)",
xlab = "Sample Means", prob = T)
lines(density(sample_means_exp1), col = "darkblue", lwd = 2)
```

Draw 1000 (N) samples of size 50 (n) from an underlying exponential distribution with parameter lambda = 0.3.
ä»å‚æ•° lambda = 0.3 çš„æŒ‡æ•°åˆ†å¸ƒä¸­æŠ½å– 1000 (N) ä¸ªå¤§å°ä¸º 50 (n) çš„æ ·æœ¬ã€‚

```{r}
# define parameters
n = 50
N = 1000
lambda = 0.3
set.seed(2)

# create vector of sample means
sample_means_exp1 = c()
for(i in 1:N){
sample_means_exp1[i] = mean(rexp(n, lambda))
}
```

Calculate their means and variances and draw a histogram to vizualize the sample mean distribution.

```{r,message=TRUE}
mean(sample_means_exp1)
var(sample_means_exp1)
hist(sample_means_exp1,
main = "Samples of Size n = 50 from Exp(0.3)",
xlab = "Sample Means", prob = T)
lines(density(sample_means_exp1), col = "darkblue", lwd = 2)
```

### Confidence Intervals

Construct a 95% CI for the population mean with ğ‘› = 10, ğ‘‹ = 175, and known (population)
ğœ = 15.
åœ¨ğ‘› = 10ã€ğ‘‹ = 175 å’Œå·²çŸ¥ï¼ˆäººå£ï¼‰ğœ = 15 çš„æ¡ä»¶ä¸‹ï¼Œæ„å»ºäººå£å¹³å‡å€¼çš„ 95% CIã€‚

```{r,message=FALSE}
lower = 175 - qnorm(0.975) * 15/sqrt(10)
upper = 175 + qnorm(0.975) * 15/sqrt(10)
c(lower, upper)
```

Construct a 99% CI for the population mean with ğ‘› = 10, ğ‘‹ = 175, and known (population) ğœ = 15.

```{r,message=FALSE}
lower = 175 - qnorm(0.995) * 15/sqrt(10)
upper = 175 + qnorm(0.995) * 15/sqrt(10)
c(lower, upper)
```

Construct a 95% CI for the population mean with ğ‘› = 10, ğ‘‹ = 175, ğ‘‘ğ‘“ = 10 - 1 = 9 and
known (sample) ğ‘  = 15.

```{r,message=FALSE}
lower = 175 - qt(0.975, df = 9) * 15/sqrt(10)
upper = 175 + qt(0.975, df = 9) * 15/sqrt(10)
c(lower, upper)
```

Construct a 95% CI for the population variance with known s = 15.

```{r,message=FALSE}
lower = 9*(15^2) / qchisq(0.975, 9)
upper = 9*(15^2) / qchisq(0.025, 9)
c(lower, upper)
```

### Hypothesis Testing

Calculate the test statistic for testing if the population mean is different from 25 given ğ‘‹ = 16, ğ‘  = 10, and ğ‘› = 40. Compare to the critical value and calculate the p-value at the 0.05 level.
ç»™å®š ğ‘‹ = 16ï¼Œğ‘  = 10ï¼Œğ‘› = 40ï¼Œè®¡ç®—æ£€éªŒäººå£å¹³å‡å€¼æ˜¯å¦ä¸åŒäº 25 çš„æ£€éªŒç»Ÿè®¡é‡ã€‚æ¯”è¾ƒä¸´ç•Œå€¼ï¼Œè®¡ç®— 0.05 æ°´å¹³çš„ p å€¼ã€‚

```{r,message=FALSE}
# test statistic
tstat = (16 - 25) / (10/sqrt(40))
# critical value
cv = qt(0.975, df = 40 - 1)
# p-value
pv = 2 * pt(tstat, df = 39)
# decision
ifelse(abs(tstat) > cv, "reject", "fail to reject")
```

```{r,message=FALSE}
ifelse(pv < 0.05, "reject", "fail to reject")
```

Using the â€œlowbwt_ALL.csvâ€ data, test if the true mean bwt is different than 3000g.

```{r,message=FALSE}
# load data
lowbwt = read.csv("Module 7/lowbwt_ALL.csv")
# one-sample, two-tailed t-test
t.test(lowbwt$bwt, alternative = 'two.sided', mu = 3000) # fail to reject
```

Test if the true mean is less than 3000g.

```{r,message=FALSE}
# one-sample, one-tailed t-test
t.test(lowbwt$bwt, alternative = 'less', mu = 3000) # fail to reject
```

# Module 8





















# Module 9











# Module 10













# Module 11












# Module 12

















